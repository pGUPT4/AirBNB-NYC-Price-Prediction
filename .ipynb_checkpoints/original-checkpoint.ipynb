{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/pcltk5896ts9hbxrsn2fxxyw0000gn/T/ipykernel_20391/3323849770.py:3: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('train.csv')\n",
      "/var/folders/6n/pcltk5896ts9hbxrsn2fxxyw0000gn/T/ipykernel_20391/3323849770.py:4: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df = pd.read_csv('test.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amenities'] = df['amenities'].apply(lambda x: x.strip('{').strip('}').replace('\"', '').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = {value for row in df['amenities'] for value in row}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = list(amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_exploded1 = df.explode('amenities')\n",
    "\n",
    "# one_hot_encoded1 = pd.get_dummies(df_exploded1['amenities'], prefix='amenities')\n",
    "\n",
    "# df_encoded1 = pd.concat([df_exploded1, one_hot_encoded1], axis=1)\n",
    "\n",
    "# df_aggregated1 = df_encoded1.groupby(level=0).sum()\n",
    "\n",
    "# amenities_cleaned = pd.concat([df, df_aggregated1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(amenities)):\n",
    "#     idk[amenities[i]] = idk['amenities'].apply(lambda x: x[i])\n",
    "#     test_df[amenities[i]] = test_df['amenities'].apply(lambda x: x[i])\n",
    "\n",
    "# test_df['amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amenities_j'] = df['amenities'].apply(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_tags = vectorizer.fit_transform(df['amenities_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_to_float(percentage):\n",
    "    if type(percentage) == str:\n",
    "        stripped = percentage.strip('%')\n",
    "        value = float(stripped) / 100 \n",
    "        return value\n",
    "\n",
    "df['host_response_rate'] = df['host_response_rate'].apply(lambda x: percentage_to_float(x))\n",
    "\n",
    "df['extra_people'] = df['extra_people'].apply(lambda x: x.strip('$'))\n",
    "\n",
    "df['host_listings_count'] = df['host_listings_count'].fillna(0).astype(int)\n",
    "\n",
    "df['bedrooms'] = df['bedrooms'].fillna(0).astype(int)\n",
    "\n",
    "df['beds'] = df['beds'].fillna(0).astype(int)\n",
    "\n",
    "df['square_feet'] = df['square_feet'].fillna(0).astype(float)\n",
    "\n",
    "df['review_scores_rating'] = df['review_scores_rating'].fillna(0).astype(int)\n",
    "\n",
    "df['review_scores_cleanliness'] = df['review_scores_cleanliness'].fillna(0).astype(int)\n",
    "\n",
    "df['review_scores_checkin'] = df['review_scores_checkin'].fillna(0).astype(int)\n",
    "\n",
    "df['review_scores_communication'] = df['review_scores_communication'].fillna(0).astype(int)\n",
    "\n",
    "df['review_scores_location'] = df['review_scores_location'].fillna(0).astype(int)\n",
    "\n",
    "df['review_scores_value'] = df['review_scores_value'].fillna(0).astype(int)\n",
    "\n",
    "# df['host_is_superhost'] = df['host_is_superhost'].replace({'f': 0, 't': 1})\n",
    "\n",
    "# df['host_identity_verified'] = df['host_identity_verified'].replace({'f': 0, 't': 1})\n",
    "\n",
    "# df['instant_bookable'] = df['instant_bookable'].replace({'f': 0, 't': 1})\n",
    "\n",
    "# df['require_guest_profile_picture'] = df['require_guest_profile_picture'].replace({'f': 0, 't': 1})\n",
    "\n",
    "# df['require_guest_phone_verification'] = df['require_guest_phone_verification'].replace({'f': 0, 't': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "def to_float(s):\n",
    "    try:\n",
    "        ret = float(s)\n",
    "    except:\n",
    "        ret = -1\n",
    "    if isnan(ret):\n",
    "        ret = -1\n",
    "    return ret\n",
    "\n",
    "def to_int(s):\n",
    "    try:\n",
    "        ret = int(s)\n",
    "    except:\n",
    "        ret = -1\n",
    "    return ret\n",
    "\n",
    "categories = [x for x in list(set(df['neighbourhood_group_cleansed'])) if type(x) is str]\n",
    "\n",
    "def create_feature(row):\n",
    "    guest_num = to_int(row.guests_included)\n",
    "    guest_cap = to_int(row.extra_people)\n",
    "    bedrooms = to_int(row.bedrooms)\n",
    "    bathrooms = to_int(row.bathrooms)\n",
    "    review = to_float(row.review_scores_rating)\n",
    "    rate = to_float(row.host_response_rate)\n",
    "    extra = to_float(row.extra_people)\n",
    "    list_count = to_int(row.host_listings_count)\n",
    "    bathrooms = to_float(row.bathrooms)\n",
    "    bedrooms = to_int(row.bedrooms)\n",
    "    beds = to_int(row.beds)\n",
    "    accommodates = to_int(row.accommodates)\n",
    "    sq_feet = to_float(row.square_feet)\n",
    "    guests = to_int(row.guests_included)\n",
    "    min_nights = to_int(row.minimum_nights)\n",
    "    max_nights = to_int(row.maximum_nights)\n",
    "    rev_rating = to_int(row.review_scores_rating)\n",
    "    clean = to_int(row.review_scores_cleanliness)\n",
    "    check_in = to_int(row.review_scores_checkin)\n",
    "    comm = to_int(row.review_scores_communication)\n",
    "    location = to_int(row.review_scores_location)\n",
    "    rev_value = to_int(row.review_scores_value)\n",
    "    # superhost = to_float(row.host_is_superhost)\n",
    "    # host_ver = to_int(row.host_identity_verified)\n",
    "    # instant = to_int(row.instant_bookable)\n",
    "    # guest_pp = to_int(row.require_guest_profile_picture)\n",
    "    # guest_ver = to_int(row.require_guest_phone_verification)\n",
    "    one_hot = [int(row.neighbourhood_group_cleansed == category) for category in categories]\n",
    "    \n",
    "    return [guest_num, guest_cap, bedrooms, bathrooms, review, rate, extra, list_count, bathrooms, \\\n",
    "            bedrooms, beds, accommodates, sq_feet, guests, min_nights, max_nights, rev_rating, clean, \\\n",
    "                check_in, comm, location, rev_value] + one_hot\n",
    "\n",
    "train_X, train_y = [], []\n",
    "for (idx, row) in df.iterrows():\n",
    "    price = float(row.price)\n",
    "    feature = create_feature(row)\n",
    "\n",
    "    train_X.append(feature)\n",
    "    train_y.append(price)\n",
    "\n",
    "#print(len(train_X), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hstack(x_tags, train_X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_construct.py:535\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices horizontally (column wise)\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m \n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bmat([blocks], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_construct.py:618\u001b[0m, in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    615\u001b[0m blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(blocks, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks must be 2-D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    620\u001b[0m M,N \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# check for fast path cases\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "hstack(x_tags, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catboost.CatBoostRegressor()  \n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_X = [], []\n",
    "for (idx, row) in test_df.iterrows():\n",
    "    feature = create_feature(row)\n",
    "    test_ids.append(row.id)\n",
    "    test_X.append(feature)\n",
    "test_y = model.predict(test_X)\n",
    "#test_y = regr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_class = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# rf_class.fit(train_X, train_y)\n",
    "\n",
    "# test_y = rf_class.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame()\n",
    "output_df['Id'] = test_ids\n",
    "output_df['Predicted'] = test_y\n",
    "output_df.to_csv('simple_linear_regression_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.mean(list(df['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame()\n",
    "output_df['Id'] = test_ids\n",
    "output_df['Predicted'] = [mean for i in range(len(test_ids))]\n",
    "output_df.to_csv('mean_value_baseline.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
